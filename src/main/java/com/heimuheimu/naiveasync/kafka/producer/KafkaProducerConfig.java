/*
 * The MIT License (MIT)
 *
 * Copyright (c) 2017 heimuheimu
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all
 * copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

package com.heimuheimu.naiveasync.kafka.producer;

import org.apache.kafka.common.serialization.ByteArraySerializer;

import java.util.HashMap;
import java.util.Map;

/**
 * Kafka 生产者配置信息，更多内容可参考文档：<a href="http://kafka.apache.org/documentation/#producerconfigs">http://kafka.apache.org/documentation/#producerconfigs</a>。
 *
 * <p><strong>说明：</strong>{@code KafkaProducerConfig} 类是非线程安全的，不允许多个线程使用同一个实例。</p>
 *
 * @author heimuheimu
 */
public class KafkaProducerConfig {

    /**
     * Kafka 生产者确认消息被送达的模式，默认为 1，允许的值为：0、1、-1、all。
     *
     * <p>
     * The number of acknowledgments the producer requires the leader to have received before considering a request complete.
     * This controls the durability of records that are sent. The following settings are allowed:
     * <ul>
     * <li>
     *     acks=0 If set to zero then the producer will not wait for any acknowledgment from the server at all.
     *     The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that
     *     the server has received the record in this case, and the retries configuration will not take effect
     *     (as the client won't generally know of any failures). The offset given back for each record will always be set to -1.
     * </li>
     * <li>
     *     acks=1 This will mean the leader will write the record to its local log but will respond without awaiting
     *     full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging
     *     the record but before the followers have replicated it then the record will be lost.
     * </li>
     * <li>
     *     acks=all This means the leader will wait for the full set of in-sync replicas to acknowledge the record.
     *     This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.
     *     This is the strongest available guarantee. This is equivalent to the acks=-1 setting.
     * </li>
     * </ul>
     * </p>
     */
    private String acks = "1";

    /**
     * Kafka 集群启动地址，例如：host1:port1,host2:port2,...
     *
     * <p>
     *     A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
     *     The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this
     *     list only impacts the initial hosts used to discover the full set of servers. This list should be in the
     *     form host1:port1,host2:port2,.... Since these servers are just used for the initial connection to discover
     *     the full cluster membership (which may change dynamically), this list need not contain the full set of
     *     servers (you may want more than one, though, in case a server is down).
     * </p>
     */
    private String bootstrapServers = "";

    /**
     * 在消息发送至 Kafka 之前，生产者允许使用的最大缓存大小，默认为 33554432 字节（32 MB）
     *
     * <p>
     * The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
     * If records are sent faster than they can be delivered to the server the producer will block for max.block.ms after
     * which it will throw an exception.
     * <br><br>This setting should correspond roughly to the total memory the producer will use, but is not a hard bound
     * since not all memory the producer uses is used for buffering. Some additional memory will be used for
     * compression (if compression is enabled) as well as for maintaining in-flight requests.
     * </p>
     */
    private long bufferMemory = 33554432;

    /**
     * 生产者数据压缩类型，默认为 "none"，允许的值为：none、gzip、snappy、lz4
     *
     * <p>
     * The compression type for all data generated by the producer. The default is none (i.e. no compression).
     * Valid values are none, gzip, snappy, or lz4. Compression is of full batches of data, so the efficacy of batching
     * will also impact the compression ratio (more batching means better compression).
     * </p>
     */
    private String compressionType = "none";

    /**
     * 消息发送失败是否进行重试，如果该值大于 0，则需要进行重试，默认为 0，不重试
     *
     * <p>
     * Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially
     * transient error. Note that this retry is no different than if the client resent the record upon receiving the error.
     * Allowing retries without setting max.in.flight.requests.per.connection to 1 will potentially change the ordering
     * of records because if two batches are sent to a single partition, and the first fails and is retried but the
     * second succeeds, then the records in the second batch may appear first.
     * </p>
     */
    private int retries = 0;

    /**
     * 合并后的消息最大字节数，默认为 16384 字节（16 KB）
     *
     * <p>
     * The producer will attempt to batch records together into fewer requests whenever multiple records are being sent
     * to the same partition. This helps performance on both the client and the server. This configuration controls
     * the default batch size in bytes.
     * <br><br>No attempt will be made to batch records larger than this size.
     * <br><br>Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.
     * <br><br>A small batch size will make batching less common and may reduce throughput (a batch size of zero will
     * disable batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate
     * a buffer of the specified batch size in anticipation of additional records.
     * </p>
     */
    private int batchSize = 16384;

    /**
     * 生产者 ID，用于在 Kafka 服务中追踪请求来源，默认为空字符串
     *
     * <p>
     * An id string to pass to the server when making requests. The purpose of this is to be able to track the source
     * of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
     * </p>
     */
    private String clientId = "";

    /**
     * 连接最大空闲时间，默认为 540000 毫秒（8 分钟）
     *
     * <p>
     * Close idle connections after the number of milliseconds specified by this config.
     * </p>
     */
    private long connectionsMaxIdleMs = 540000;

    /**
     * 消息发送延迟时间，默认为 0 毫秒（不延迟）
     *
     * <p>
     * The producer groups together any records that arrive in between request transmissions into a single batched request.
     * Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances
     * the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding
     * a small amount of artificial delay—that is, rather than immediately sending out a record the producer will wait for up
     * to the given delay to allow other records to be sent so that the sends can be batched together. This can be thought
     * of as analogous to Nagle's algorithm in TCP. This setting gives the upper bound on the delay for batching:
     * once we get batch.size worth of records for a partition it will be sent immediately regardless of this setting,
     * however if we have fewer than this many bytes accumulated for this partition we will 'linger' for the specified
     * time waiting for more records to show up. This setting defaults to 0 (i.e. no delay). Setting linger.ms=5,
     * for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency
     * to records sent in the absence of load.
     * </p>
     */
    private long lingerMs = 0;

    /**
     * KafkaProducer.send() 或 KafkaProducer.partitionsFor() 方法最大阻塞时间，默认为 60000 毫秒（60 秒）
     *
     * <p>
     * The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block.
     * These methods can be blocked either because the buffer is full or metadata unavailable.Blocking in the user-supplied
     * serializers or partitioner will not be counted against this timeout.
     * </p>
     */
    private long maxBlockMs = 60000;

    /**
     * 每次消息发送请求允许的最大字节数，默认为 1048576 字节（1 MB）
     *
     * <p>
     * The maximum size of a request in bytes. This setting will limit the number of record batches the producer
     * will send in a single request to avoid sending huge requests. This is also effectively a cap on the maximum
     * record batch size. Note that the server has its own cap on record batch size which may be different from this.
     * </p>
     */
    private int maxRequestSize = 1048576;

    /**
     * Socket 读取缓存大小，默认为 32768 字节（32 KB）
     *
     * <p>
     * The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
     * </p>
     */
    private int receiveBufferBytes = 32768;

    /**
     * 请求超时时间，默认为 30000 毫秒（30 秒）
     *
     * <p>
     * The configuration controls the maximum amount of time the client will wait for the response of a request.
     * If the response is not received before the timeout elapses the client will resend the request if necessary
     * or fail the request if retries are exhausted. This should be larger than replica.lag.time.max.ms (a broker configuration)
     * to reduce the possibility of message duplication due to unnecessary producer retries.
     * </p>
     */
    private int requestTimeoutMs = 30000;

    /**
     * Socket 写入缓存大小，默认为 131072 字节（128 KB）
     *
     * <p>
     * The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.
     * </p>
     */
    private int sendBufferBytes = 131072;

    /**
     * 获得 Kafka 生产者确认消息被送达的模式，默认为 1（Leader 写入成功即认为成功）。
     *
     * @return Kafka 生产者确认消息被送达的模式
     */
    public String getAcks() {
        return acks;
    }

    /**
     * 设置 Kafka 生产者确认消息被送达的模式，允许的值为：0、1、-1、all。
     *
     * <p>
     * The number of acknowledgments the producer requires the leader to have received before considering a request complete.
     * This controls the durability of records that are sent. The following settings are allowed:
     * </p>
     * <ul>
     * <li>
     *     acks=0 If set to zero then the producer will not wait for any acknowledgment from the server at all.
     *     The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that
     *     the server has received the record in this case, and the retries configuration will not take effect
     *     (as the client won't generally know of any failures). The offset given back for each record will always be set to -1.
     * </li>
     * <li>
     *     acks=1 This will mean the leader will write the record to its local log but will respond without awaiting
     *     full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging
     *     the record but before the followers have replicated it then the record will be lost.
     * </li>
     * <li>
     *     acks=all This means the leader will wait for the full set of in-sync replicas to acknowledge the record.
     *     This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.
     *     This is the strongest available guarantee. This is equivalent to the acks=-1 setting.
     * </li>
     * </ul>
     *
     * @param acks Kafka 生产者确认消息被送达的模式
     */
    public void setAcks(String acks) {
        this.acks = acks;
    }

    /**
     * 获得 Kafka 集群启动地址，例如：host1:port1,host2:port2,...
     *
     * @return Kafka 集群启动地址
     */
    public String getBootstrapServers() {
        return bootstrapServers;
    }

    /**
     * 设置 Kafka 集群启动地址，例如：host1:port1,host2:port2,...
     *
     * <p>
     *     A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
     *     The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this
     *     list only impacts the initial hosts used to discover the full set of servers. This list should be in the
     *     form host1:port1,host2:port2,.... Since these servers are just used for the initial connection to discover
     *     the full cluster membership (which may change dynamically), this list need not contain the full set of
     *     servers (you may want more than one, though, in case a server is down).
     * </p>
     *
     * @param bootstrapServers Kafka 集群启动地址
     */
    public void setBootstrapServers(String bootstrapServers) {
        this.bootstrapServers = bootstrapServers;
    }

    /**
     * 获得生产者允许使用的最大缓存大小，默认为 33554432 字节（32 MB）。
     *
     * @return 生产者允许使用的最大缓存大小
     */
    public long getBufferMemory() {
        return bufferMemory;
    }

    /**
     * 设置生产者允许使用的最大缓存大小。
     *
     * <p>
     * The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
     * If records are sent faster than they can be delivered to the server the producer will block for max.block.ms after
     * which it will throw an exception.
     * <br><br>This setting should correspond roughly to the total memory the producer will use, but is not a hard bound
     * since not all memory the producer uses is used for buffering. Some additional memory will be used for
     * compression (if compression is enabled) as well as for maintaining in-flight requests.
     * </p>
     *
     * @param bufferMemory 生产者允许使用的最大缓存大小
     */
    public void setBufferMemory(long bufferMemory) {
        this.bufferMemory = bufferMemory;
    }

    /**
     * 获得生产者数据压缩类型，默认为 "none"（不压缩）。
     *
     * @return 生产者数据压缩类型
     */
    public String getCompressionType() {
        return compressionType;
    }

    /**
     * 设置生产者数据压缩类型，允许的值为：none、gzip、snappy、lz4。
     *
     * <p>
     * The compression type for all data generated by the producer. The default is none (i.e. no compression).
     * Valid values are none, gzip, snappy, or lz4. Compression is of full batches of data, so the efficacy of batching
     * will also impact the compression ratio (more batching means better compression).
     * </p>
     *
     * @param compressionType 生产者数据压缩类型
     */
    public void setCompressionType(String compressionType) {
        this.compressionType = compressionType;
    }

    /**
     * 获得消息发送失败是否进行重试，默认为 0，不重试。
     *
     * @return 息发送失败是否进行重试
     */
    public int getRetries() {
        return retries;
    }

    /**
     * 设置消息发送失败是否进行重试，如果该值大于 0，则需要进行重试，如果为 0，则不重试。
     *
     * <p>
     * Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially
     * transient error. Note that this retry is no different than if the client resent the record upon receiving the error.
     * Allowing retries without setting max.in.flight.requests.per.connection to 1 will potentially change the ordering
     * of records because if two batches are sent to a single partition, and the first fails and is retried but the
     * second succeeds, then the records in the second batch may appear first.
     * </p>
     *
     * @param retries 消息发送失败是否进行重试
     */
    public void setRetries(int retries) {
        this.retries = retries;
    }

    /**
     * 获得合并后的消息最大字节数，默认为 16384 字节（16 KB）。
     *
     * @return 合并后的消息最大字节数
     */
    public int getBatchSize() {
        return batchSize;
    }

    /**
     * 设置合并后的消息最大字节数。
     *
     * <p>
     * The producer will attempt to batch records together into fewer requests whenever multiple records are being sent
     * to the same partition. This helps performance on both the client and the server. This configuration controls
     * the default batch size in bytes.
     * <br><br>No attempt will be made to batch records larger than this size.
     * <br><br>Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.
     * <br><br>A small batch size will make batching less common and may reduce throughput (a batch size of zero will
     * disable batching entirely). A very large batch size may use memory a bit more wastefully as we will always allocate
     * a buffer of the specified batch size in anticipation of additional records.
     * </p>
     *
     * @param batchSize 合并后的消息最大字节数
     */
    public void setBatchSize(int batchSize) {
        this.batchSize = batchSize;
    }

    /**
     * 获得生产者 ID，用于在 Kafka 服务中追踪请求来源，默认为空字符串。
     *
     * @return 生产者 ID
     */
    public String getClientId() {
        return clientId;
    }

    /**
     * 设置生产者 ID，用于在 Kafka 服务中追踪请求来源，允许空字符串。
     *
     * <p>
     * An id string to pass to the server when making requests. The purpose of this is to be able to track the source
     * of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
     * </p>
     *
     * @param clientId 生产者 ID，允许空字符串
     */
    public void setClientId(String clientId) {
        this.clientId = clientId;
    }

    /**
     * 获得连接最大空闲时间，默认为 540000 毫秒（8 分钟）。
     *
     * @return 连接最大空闲时间
     */
    public long getConnectionsMaxIdleMs() {
        return connectionsMaxIdleMs;
    }

    /**
     * 设置连接最大空闲时间，单位：毫秒。
     *
     * <p>
     * Close idle connections after the number of milliseconds specified by this config.
     * </p>
     *
     * @param connectionsMaxIdleMs 连接最大空闲时间
     */
    public void setConnectionsMaxIdleMs(long connectionsMaxIdleMs) {
        this.connectionsMaxIdleMs = connectionsMaxIdleMs;
    }

    /**
     * 获得消息发送延迟时间，默认为 0 毫秒（不延迟）。
     *
     * @return 消息发送延迟时间
     */
    public long getLingerMs() {
        return lingerMs;
    }

    /**
     * 设置消息发送延迟时间，单位：毫秒。
     *
     * <p>
     * The producer groups together any records that arrive in between request transmissions into a single batched request.
     * Normally this occurs only under load when records arrive faster than they can be sent out. However in some circumstances
     * the client may want to reduce the number of requests even under moderate load. This setting accomplishes this by adding
     * a small amount of artificial delay—that is, rather than immediately sending out a record the producer will wait for up
     * to the given delay to allow other records to be sent so that the sends can be batched together. This can be thought
     * of as analogous to Nagle's algorithm in TCP. This setting gives the upper bound on the delay for batching:
     * once we get batch.size worth of records for a partition it will be sent immediately regardless of this setting,
     * however if we have fewer than this many bytes accumulated for this partition we will 'linger' for the specified
     * time waiting for more records to show up. This setting defaults to 0 (i.e. no delay). Setting linger.ms=5,
     * for example, would have the effect of reducing the number of requests sent but would add up to 5ms of latency
     * to records sent in the absence of load.
     * </p>
     *
     * @param lingerMs 消息发送延迟时间
     */
    public void setLingerMs(long lingerMs) {
        this.lingerMs = lingerMs;
    }

    /**
     * 获得 KafkaProducer.send() 或 KafkaProducer.partitionsFor() 方法最大阻塞时间，默认为 60000 毫秒（60 秒）。
     *
     * @return KafkaProducer.send() 或 KafkaProducer.partitionsFor() 方法最大阻塞时间
     */
    public long getMaxBlockMs() {
        return maxBlockMs;
    }

    /**
     * 设置 KafkaProducer.send() 或 KafkaProducer.partitionsFor() 方法最大阻塞时间，单位：毫秒。
     *
     * <p>
     * The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block.
     * These methods can be blocked either because the buffer is full or metadata unavailable.Blocking in the user-supplied
     * serializers or partitioner will not be counted against this timeout.
     * </p>
     *
     * @param maxBlockMs KafkaProducer.send() 或 KafkaProducer.partitionsFor() 方法最大阻塞时间
     */
    public void setMaxBlockMs(long maxBlockMs) {
        this.maxBlockMs = maxBlockMs;
    }

    /**
     * 获得每次消息发送请求允许的最大字节数，默认为 1048576 字节（1 MB）。
     *
     * @return 每次消息发送请求允许的最大字节数
     */
    public int getMaxRequestSize() {
        return maxRequestSize;
    }

    /**
     * 设置每次消息发送请求允许的最大字节数。
     *
     * <p>
     * The maximum size of a request in bytes. This setting will limit the number of record batches the producer
     * will send in a single request to avoid sending huge requests. This is also effectively a cap on the maximum
     * record batch size. Note that the server has its own cap on record batch size which may be different from this.
     * </p>
     *
     * @param maxRequestSize 每次消息发送请求允许的最大字节数
     */
    public void setMaxRequestSize(int maxRequestSize) {
        this.maxRequestSize = maxRequestSize;
    }

    /**
     * 获得 Socket 读取缓存大小，默认为 32768 字节（32 KB）。
     *
     * @return Socket 读取缓存大小
     */
    public int getReceiveBufferBytes() {
        return receiveBufferBytes;
    }

    /**
     * 设置 Socket 读取缓存大小。
     *
     * <p>
     * The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
     * </p>
     *
     * @param receiveBufferBytes Socket 读取缓存大小
     */
    public void setReceiveBufferBytes(int receiveBufferBytes) {
        this.receiveBufferBytes = receiveBufferBytes;
    }

    /**
     * 获得请求超时时间，默认为 30000 毫秒（30 秒）。
     *
     * @return 请求超时时间
     */
    public int getRequestTimeoutMs() {
        return requestTimeoutMs;
    }

    /**
     * 设置请求超时时间，单位：毫秒。
     *
     * <p>
     * The configuration controls the maximum amount of time the client will wait for the response of a request.
     * If the response is not received before the timeout elapses the client will resend the request if necessary
     * or fail the request if retries are exhausted. This should be larger than replica.lag.time.max.ms (a broker configuration)
     * to reduce the possibility of message duplication due to unnecessary producer retries.
     * </p>
     *
     * @param requestTimeoutMs 请求超时时间
     */
    public void setRequestTimeoutMs(int requestTimeoutMs) {
        this.requestTimeoutMs = requestTimeoutMs;
    }

    /**
     * 获得 Socket 写入缓存大小，默认为 131072 字节（128 KB）。
     *
     * @return Socket 写入缓存大小
     */
    public int getSendBufferBytes() {
        return sendBufferBytes;
    }

    /**
     * 设置 Socket 写入缓存大小。
     *
     * <p>
     * The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.
     * </p>
     *
     * @param sendBufferBytes Socket 写入缓存大小
     */
    public void setSendBufferBytes(int sendBufferBytes) {
        this.sendBufferBytes = sendBufferBytes;
    }

    /**
     * 根据当前配置信息返回一个用于构造 {@link org.apache.kafka.clients.producer.Producer} 实例的配置信息 {@code Map}。
     *
     * @return Kafka 配置信息 {@code Map}
     */
    public Map<String, Object> toConfigMap() {
        HashMap<String, Object> configMap = new HashMap<>();
        configMap.put("bootstrap.servers", bootstrapServers);
        configMap.put("key.serializer", ByteArraySerializer.class);
        configMap.put("value.serializer", ByteArraySerializer.class);
        configMap.put("acks", acks);
        configMap.put("buffer.memory", bufferMemory);
        configMap.put("compression.type", compressionType);
        configMap.put("retries", retries);
        configMap.put("batch.size", batchSize);
        configMap.put("client.id", clientId);
        configMap.put("connections.max.idle.ms", connectionsMaxIdleMs);
        configMap.put("linger.ms", lingerMs);
        configMap.put("max.block.ms", maxBlockMs);
        configMap.put("max.request.size", maxRequestSize);
        configMap.put("receive.buffer.bytes", receiveBufferBytes);
        configMap.put("request.timeout.ms", requestTimeoutMs);
        configMap.put("send.buffer.bytes", sendBufferBytes);
        return configMap;
    }

    @Override
    public String toString() {
        return "KafkaProducerConfig{" +
                "acks='" + acks + '\'' +
                ", bootstrapServers='" + bootstrapServers + '\'' +
                ", bufferMemory=" + bufferMemory +
                ", compressionType='" + compressionType + '\'' +
                ", retries=" + retries +
                ", batchSize=" + batchSize +
                ", clientId='" + clientId + '\'' +
                ", connectionsMaxIdleMs=" + connectionsMaxIdleMs +
                ", lingerMs=" + lingerMs +
                ", maxBlockMs=" + maxBlockMs +
                ", maxRequestSize=" + maxRequestSize +
                ", receiveBufferBytes=" + receiveBufferBytes +
                ", requestTimeoutMs=" + requestTimeoutMs +
                ", sendBufferBytes=" + sendBufferBytes +
                '}';
    }
}
